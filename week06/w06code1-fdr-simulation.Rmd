---
title: "FDR Simulation"
author: "ks"
date: "6/24/2020"
output: html_document
---

# {.tabset}

## Simulation set up 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(genefilter)
library(qvalue)
library(limma)
library(tidyverse)
```

First I'll get the real data and analyze it. This will just be for the analysis of hormone response genes using the non-specific knockdown group.
```{r jbcdat}
load(file = c("data/JBC 2012/jbcdat.rda"))
geoid <- rownames(jbcdat$targets)[jbcdat$targets$treatment == "siNS"]
subsetEobj <- function(dataobj,geonames){
  subobj <-NULL
     subobj$targets <- dataobj$targets[geonames,]
     subobj$E       <- dataobj$E[,geonames]
     subobj$genes   <- dataobj$genes
     subobj
}
siNSobj <- subsetEobj(jbcdat,geoid)

design <- model.matrix(~factor(siNSobj$targets$hour))
fit  <- limma::lmFit(siNSobj$E,design)
efit <- limma::eBayes(fit)
sds <- sqrt(efit$s2.post)
```


I will the following default design settings:   

* 100 samples

* 10,000 genes:  2500 differentially expressed, 7500 null 

* 75\% genes are truly null ($\pi_0$)

```{r design-vals}
nsamp <- 100       # number of samples
n1     <- nsamp/2    # equal sample sizes in each group
ng     <- 10000     # number of genes
pinull    <- 0.75      # proportion of null genes
G0     <- ng*pinull  # number of null genes
set.seed(99)
ssds <- sample(sds,ng) # sample, and randomize the order
```

Here are 2 functions I will use. The first will simulate the data as either from the null (without loss of generality, mean=0) or from the alternative (mean = delta).
```{r simdat}
simdat <- function(se,delta=0.02,nsamp=100,ng=10000,mn=0,pi0=0.75){
  n1 <- nsamp/2   
  gp  <- factor(rep(c("group1", "group2"), each=n1))
    sdat <- replicate(nsamp,rnorm(n = ng, mean = mn, sd = se))
     deg <- rep(0,ng)
     # differential expressed genes (deg) occur in first G1 rows
      G1 <- ng*(1-pi0)
  deg[1:G1] <- 1
  sdat[c(1:G1),c(1:n1)] <- sdat[c(1:G1),c(1:n1)] + delta
    
  list(E=sdat,targets=gp,genes=deg)
}

est.error=function(test.out,truth){
	TP=test.out*truth
	FP=test.out*(1-truth)
	nTP=sum(TP)
	nFP=sum(FP)
	
	list(TP=nTP,FP=nFP,FDR=nFP/(nFP+nTP),power=nTP/sum(truth))
}
```


## 1 Data set ($\pi_0=75\%$; **G=10,000**)

Now let's simulate some data, analyze, and plot the estimated false-discovery rate (BH adjusted p & qvalue) as a function of the true FDR.
```{r rsimdat}
set.seed(88)  
sim1 <- simdat(ssds,delta=0.11)
tt=rowttests(sim1$E,sim1$targets)
qobj=qvalue(tt$p.value)
wtt <- tt %>%
        mutate(BH.adjp=p.adjust(tt$p.value,method="BH"),
                 qvalue=qobj$qvalue,
                 truedeg = sim1$genes,
                 nullgene = 1-sim1$genes,
                 n = 1)
head(wtt,n=3)
```

Now I need to count the number of true positives and false positives for each unique FDR adjusted p estimate. I do this by sorting the pvalues, and using the cumulative sum command.  
```{r countresults2}
wtt <- wtt %>% 
       arrange(p.value) 
ntt <- wtt %>%
        select(BH.adjp,qvalue,truedeg,nullgene,n) %>%
        mutate(n_tp = cumsum(truedeg),
               n_fd = cumsum(nullgene),
               n_t  = cumsum(n))   %>%
        group_by(BH.adjp)  %>%
          slice(which.max(n_t)) %>%
       mutate( FDR = n_fd/n_t,
               pwr = n_tp/ng/(1-pinull))
```

And I can plot the results.

```{r fig2}
par(mfrow=c(1,2))
plot(ntt$FDR,ntt$BH.adjp,type="s",xlab="True FDR",ylab="Estimated FDR",lty=3,xlim=c(0,0.75),axes=F)
axis(1,at=c(0,.25,.5,.75))
axis(2)
box()
lines(ntt$FDR,ntt$qvalue,type="s",lty=2)
#legend(0,1,c("BH","qvalue"),lty=c(2,3))
abline(0,1)

plot(ntt$BH.adjp,ntt$pwr,type="s",xlab="Estimated FDR",
	ylab="Power",lty=3)
lines(ntt$qvalue,ntt$pwr,type="s",lty=2)
legend(.3,.4,c("BH","qvalue"),lty=c(3,2))
```

The BH adjusted pvalue overestimates the true FDR and the q-value appears unbiased.

## 1,000 Data sets ($\pi_0=75\%$; **G=10,000**)
Now let's run this 1000 times, and summarize.

```{r simulation}
set.seed(3214)
nsim=1000
BH5p.out= cbind.data.frame(TP = rep(NA,nsim),
                           FP = rep(NA,nsim),
                           FDR = rep(NA,nsim),
                           Power = rep(NA,nsim))
BH20p.out=BH5p.out
q5p.out=cbind.data.frame(BH5p.out,pi0=rep(NA,nsim))
q20p.out=q5p.out

for (j in 1:nsim) {
  sim <- simdat(ssds,delta=0.11)
  tt=rowttests(sim$E,sim$targets)
	BH.adjp=p.adjust(tt$p.value,method="BH")
	qobj=qvalue(tt$p.value)

	BH5p.out[j,]=unlist(est.error(ifelse(BH.adjp<0.05,1,0),sim$genes))
	q5p.out[j,]=c(unlist(est.error(ifelse(qobj$qvalues<0.05,1,0),
	                               sim$genes)),
			          qobj$pi0)
	BH20p.out[j,]=unlist(est.error(ifelse(BH.adjp<0.2,1,0),sim$genes))
	q20p.out[j,]=c(unlist(est.error(ifelse(qobj$qvalues<0.2,1,0),sim$genes)),
			qobj$pi0)
}
```

Summarize the mean and 95% confidence interval limits for the 5% and 20% FDR estimates (BH adjusted p & qvalue methods).
```{r simresultsorig}
BH05.sum<- BH5p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
q05.sum<- q5p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
BH20.sum<- BH20p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
q20.sum<- q20p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
tabrslts<- rbind.data.frame(cbind.data.frame(method="bh05",row=1,BH05.sum),
                         cbind.data.frame(method="q05",row=2,q05.sum),
                         cbind.data.frame(method="bh20",row=3,BH20.sum),
                         cbind.data.frame(method="q20",row=4,q20.sum))
tabrslts
```

The 3.5\% increase in power for a q < 0.05 results in 87 more true discoveries (=0.035*2500).

Here's the estimate of $\pi_0$.
```{r estpio}
q20p.out %>%
            summarize(mpi0 = mean(pi0),
                      lbpi0 = quantile(pi0,0.05),
                      ubpi0 = quantile(pi0,0.95))
```

```{r plotestimates}
par(mfrow=c(1,2),oma=c(1,5,1,1),mar=c(4,2,3,0))
plot(tabrslts[,"mfdr"],c(1:4),xlim=c(0,0.25),pch=16,
     xlab="true FDR",ylab="",axes=F)
segments(tabrslts[,"lbfdr"],c(1:4),tabrslts[,"ubfdr"],c(1:4),lwd=2)
abline(v=0.05,lty=3)
abline(v=0.2,lty=3)
box(); axis(1); axis(2,at=c(1:4), c("BHp < 0.05","q < 0.05","BHp < 0.2","q < 0.2"),las=2)
plot(tabrslts[,"mpwr"],c(1:4),xlim=c(0.5,0.85),pch=16,
     xlab="Power",ylab="",axes=F)
segments(tabrslts[,"lbpwr"],c(1:4),tabrslts[,"ubpwr"],c(1:4),lwd=2)
box(); axis(1)
```

Yes, we see the qvalue is unbiased for estimating the FDR, whereas the BH adjusted pvalue is conservative. This small difference translates into slighly higher power using the q-value approach.

## 1 Data set ($\pi_0 = 99\%, 75\%, 50\%$)

```{r pi0simdat}
set.seed(210)  # This sets a reproducible starting point 
              # for our random number generator

sim1 <- simdat(ssds,delta=0.11,pi0=0.99)
tt=rowttests(sim1$E,sim1$targets)
qobj=qvalue(tt$p.value)
tt99 <- tt %>%
        mutate(BH.adjp=p.adjust(tt$p.value,method="BH"),
                 qvalue=qobj$qvalue,
                 truedeg = sim1$genes,
                 nullgene = 1-sim1$genes,
                 n = 1)

sim1 <- simdat(ssds,delta=0.11,pi0=0.75)
tt=rowttests(sim1$E,sim1$targets)
qobj=qvalue(tt$p.value)
tt75 <- tt %>%
        mutate(BH.adjp=p.adjust(tt$p.value,method="BH"),
                 qvalue=qobj$qvalue,
                 truedeg = sim1$genes,
                 nullgene = 1-sim1$genes,
                 n = 1)

sim1 <- simdat(ssds,delta=0.11,pi0=0.50)
tt=rowttests(sim1$E,sim1$targets)
qobj=qvalue(tt$p.value)
tt50 <- tt %>%
        mutate(BH.adjp=p.adjust(tt$p.value,method="BH"),
                 qvalue=qobj$qvalue,
                 truedeg = sim1$genes,
                 nullgene = 1-sim1$genes,
                 n = 1)
```

```{r countresults99}
ntt99 <- tt99 %>% 
       arrange(p.value)  %>%
        select(BH.adjp,qvalue,truedeg,nullgene,n) %>%
        mutate(n_tp = cumsum(truedeg),
               n_fd = cumsum(nullgene),
               n_t  = cumsum(n))   %>%
        group_by(BH.adjp)  %>%
          slice(which.max(n_t)) %>%
       mutate( FDR = n_fd/n_t,
               pwr = n_tp/ng/(1-pinull))

ntt75 <- tt75 %>% 
       arrange(p.value)  %>%
        select(BH.adjp,qvalue,truedeg,nullgene,n) %>%
        mutate(n_tp = cumsum(truedeg),
               n_fd = cumsum(nullgene),
               n_t  = cumsum(n))   %>%
        group_by(BH.adjp)  %>%
          slice(which.max(n_t)) %>%
       mutate( FDR = n_fd/n_t,
               pwr = n_tp/ng/(1-pinull))

ntt50 <- tt50 %>% 
       arrange(p.value)  %>%
        select(BH.adjp,qvalue,truedeg,nullgene,n) %>%
        mutate(n_tp = cumsum(truedeg),
               n_fd = cumsum(nullgene),
               n_t  = cumsum(n))   %>%
        group_by(BH.adjp)  %>%
          slice(which.max(n_t)) %>%
       mutate( FDR = n_fd/n_t,
               pwr = n_tp/ng/(1-pinull))
```

Plot the results.

```{r fig3}
par(mfrow=c(1,2))
plot(ntt99$FDR,ntt99$BH.adjp,type="s",main="BH adjusted p",xlab="True FDR",ylab="Estimated FDR",lty=1)
lines(ntt75$FDR,ntt75$BH.adjp,type="s",lty=2)
lines(ntt50$FDR,ntt50$BH.adjp,type="s",lty=3)
legend(.45,.3,c("pi0=0.99","pi0=0.75","pi0=0.50"),lty=c(1:3),cex=.8)
abline(0,1)

plot(ntt99$FDR,ntt99$qvalue,type="s",main="q-value",xlab="True FDR",
	ylab="Estimated FDR",lty=1)
lines(ntt75$FDR,ntt75$qvalue,type="s",lty=2)
lines(ntt50$FDR,ntt50$qvalue,type="s",lty=3)
abline(0,1)
```

The larger $\pi_0$ (closer to 1), the less biased the BH FDR adjusted pvalue as estimates of the true FDR.

## REPEAT 1 Data set ($\pi_0=75\%$; **G=100**)

Now let's simulate some data, analyze, and plot the estimated false-discovery rate (FDR) as a function of the true FDR.
```{r simdat3}
set.seed(15)  # This sets a reproducible starting point 
              # for our random number generator

sim1 <- simdat(ssds,delta=0.11,ng=200,pi0=0.75)
tt=rowttests(sim1$E,sim1$targets)
qobj=qvalue(tt$p.value)
wtt <- tt %>%
        mutate(BH.adjp=p.adjust(tt$p.value,method="BH"),
                 qvalue=qobj$qvalue,
                 truedeg = sim1$genes,
                 nullgene = 1-sim1$genes,
                 n = 1)
```
Sort the results on the pvalues and count the TPs and FPs.

```{r countresults1}
wtt <- wtt %>% 
       arrange(p.value) 
ntt <- wtt %>%
        select(BH.adjp,qvalue,truedeg,nullgene,n) %>%
        mutate(n_tp = cumsum(truedeg),
               n_fd = cumsum(nullgene),
               n_t  = cumsum(n))   %>%
        group_by(BH.adjp)  %>%
          slice(which.max(n_t)) %>%
       mutate( FDR = n_fd/n_t,
               pwr = n_tp/ng/(1-pinull))
```

Plot the results.

```{r fig1}
plot(ntt$FDR,ntt$BH.adjp,type="s",xlab="True FDR",ylab="Estimated FDR",lty=3,xlim=c(0,0.75),axes=F)
axis(1,at=c(0,.25,.5,.75))
axis(2)
box()
lines(ntt$FDR,ntt$qvalue,type="s",lty=2)
legend(0,1,c("BH","qvalue"),lty=c(3,2))
abline(0,1)
```

The qvalue underestimates the true FDR in this data set. What about on average?

## REPEAT 1,000 Data set ($\pi_0=75\%$; **G=100**)

Now let's run this 1000 times, and summarize.

```{r simulation2}
nsim=1000
BH5p.out= cbind.data.frame(TP = rep(NA,nsim),
                           FP = rep(NA,nsim),
                           FDR = rep(NA,nsim),
                           Power = rep(NA,nsim))
BH20p.out=BH5p.out
q5p.out=cbind.data.frame(BH5p.out,pi0=rep(NA,nsim))
q20p.out=q5p.out

set.seed(3) 
for (j in 1:nsim) {
  sim <- simdat(ssds,delta=0.11,ng=200,pi0=0.75)
  tt=rowttests(sim$E,sim$targets)
	BH.adjp=p.adjust(tt$p.value,method="BH")
	qobj=qvalue(tt$p.value)

	BH5p.out[j,]=unlist(est.error(ifelse(BH.adjp<0.05,1,0),sim$genes))
	q5p.out[j,]=c(unlist(est.error(ifelse(qobj$qvalues<0.05,1,0),
	                               sim$genes)),
			          qobj$pi0)
	BH20p.out[j,]=unlist(est.error(ifelse(BH.adjp<0.2,1,0),sim$genes))
	q20p.out[j,]=c(unlist(est.error(ifelse(qobj$qvalues<0.2,1,0),sim$genes)),
			qobj$pi0)
}
```



```{r simresults05}
BH05.sum<- BH5p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
q05.sum<- q5p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
BH20.sum<- BH20p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
q20.sum<- q20p.out %>%
            summarize(mfdr = mean(FDR),
                      lbfdr = quantile(FDR,0.05),
                      ubfdr = quantile(FDR,0.95),
                      mpwr = mean(Power),
                      lbpwr = quantile(Power,0.05),
                      ubpwr = quantile(Power,0.95))
tabrslts<- rbind.data.frame(cbind.data.frame(method="bh05",row=1,BH05.sum),
                         cbind.data.frame(method="q05",row=2,q05.sum),
                         cbind.data.frame(method="bh20",row=3,BH20.sum),
                         cbind.data.frame(method="q20",row=4,q20.sum))
tabrslts
```


```{r estpio2}
q20p.out %>%
            summarize(mpi0 = mean(pi0),
                      lbpi0 = quantile(pi0,0.05),
                      ubpi0 = quantile(pi0,0.95))
```

```{r plotestimates2}
par(mfrow=c(1,2),oma=c(1,5,1,1),mar=c(4,2,3,0))
plot(tabrslts[,"mfdr"],c(1:4),xlim=c(0,0.4),pch=16,
     xlab="true FDR",ylab="",axes=F)
segments(tabrslts[,"lbfdr"],c(1:4),tabrslts[,"ubfdr"],c(1:4),lwd=2)
abline(v=0.05,lty=3)
abline(v=0.2,lty=3)
box(); axis(1); axis(2,at=c(1:4), c("BHp < 0.05","q < 0.05","BHp < 0.2","q < 0.2"),las=2)
plot(tabrslts[,"mpwr"],c(1:4),xlim=c(0.45,0.95),pch=16,
     xlab="Power",ylab="",axes=F)
segments(tabrslts[,"lbpwr"],c(1:4),tabrslts[,"ubpwr"],c(1:4),lwd=2)
box(); axis(1)
```

On average, the q-value is unbiased. However, the confidence interval is huge. This is because the number of tests is too small. Storey and Tibshirani recommend a minimum of 3,000 tests before using the q-value as an FDR estimate.

```{r sessioninfo}
sessionInfo()
```
